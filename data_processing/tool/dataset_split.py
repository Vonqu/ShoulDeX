#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®é›†åˆ’åˆ†å·¥å…· - ShoulDexé¡¹ç›®
åŠŸèƒ½ï¼šå°†åŒ…å«å¤šä¸ªè¢«è¯•å’ŒåŠ¨ä½œçš„CSVæ–‡ä»¶æŒ‰æŒ‡å®šè§„åˆ™åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†

ä½œè€…ï¼šAIåŠ©æ‰‹
åˆ›å»ºæ—¶é—´ï¼š2025
ç‰ˆæœ¬ï¼š1.0
"""

import os
import glob
import pandas as pd
import numpy as np
from pathlib import Path
import random
import shutil
from typing import List, Dict, Tuple, Optional
import argparse
import json
from datetime import datetime


class DatasetSplitter:
    """æ•°æ®é›†åˆ’åˆ†ç±»"""
    
    def __init__(self, 
                 input_dir: str,
                 output_dir: str = "./data/model_training",
                 train_ratio: float = 0.8,
                 random_seed: int = 42):
        """
        åˆå§‹åŒ–æ•°æ®é›†åˆ’åˆ†å™¨
        
        Args:
            input_dir (str): è¾“å…¥æ•°æ®ç›®å½•è·¯å¾„
            output_dir (str): è¾“å‡ºç›®å½•è·¯å¾„
            train_ratio (float): è®­ç»ƒé›†æ¯”ä¾‹ï¼Œé»˜è®¤0.8
            random_seed (int): éšæœºç§å­ï¼Œé»˜è®¤42
        """
        self.input_dir = Path(input_dir)
        self.output_dir = Path(output_dir)
        self.train_ratio = train_ratio
        self.test_ratio = 1.0 - train_ratio
        self.random_seed = random_seed
        
        # è®¾ç½®éšæœºç§å­
        random.seed(random_seed)
        np.random.seed(random_seed)
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.train_dir = self.output_dir / "train"
        self.test_dir = self.output_dir / "test"
        self.train_dir.mkdir(parents=True, exist_ok=True)
        self.test_dir.mkdir(parents=True, exist_ok=True)
        
        # å­˜å‚¨åˆ’åˆ†ä¿¡æ¯
        self.split_info = {
            "input_dir": str(self.input_dir),
            "output_dir": str(self.output_dir),
            "train_ratio": self.train_ratio,
            "test_ratio": self.test_ratio,
            "random_seed": self.random_seed,
            "split_time": datetime.now().isoformat(),
            "train_files": [],
            "test_files": [],
            "statistics": {}
        }
    
    def scan_files(self) -> List[Path]:
        """
        æ‰«æè¾“å…¥ç›®å½•ä¸­çš„æ‰€æœ‰CSVæ–‡ä»¶
        
        Returns:
            List[Path]: CSVæ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        csv_files = []
        
        # é€’å½’æœç´¢æ‰€æœ‰CSVæ–‡ä»¶
        for pattern in ["**/*.csv", "*.csv"]:
            csv_files.extend(list(self.input_dir.glob(pattern)))
        
        print(f"ğŸ“ åœ¨ {self.input_dir} ä¸­æ‰¾åˆ° {len(csv_files)} ä¸ªCSVæ–‡ä»¶")
        
        # æŒ‰æ–‡ä»¶åæ’åºï¼Œç¡®ä¿ç»“æœå¯é‡ç°
        csv_files.sort()
        
        return csv_files
    
    def parse_filename(self, filepath: Path) -> Dict[str, str]:
        """
        è§£ææ–‡ä»¶åï¼Œæå–è¢«è¯•IDã€åŠ¨ä½œç±»å‹ç­‰ä¿¡æ¯
        
        æ–‡ä»¶åæ ¼å¼ç¤ºä¾‹ï¼š
        - P1_AB_fps30.csv -> è¢«è¯•P1ï¼ŒåŠ¨ä½œABï¼Œå…¶ä»–fps30
        - P2_C_RH_fps30_jianjiagu.csv -> è¢«è¯•P2ï¼ŒåŠ¨ä½œç±»å‹C_RHï¼Œå…¶ä»–fps30_jianjiagu
        
        Args:
            filepath (Path): æ–‡ä»¶è·¯å¾„
            
        Returns:
            Dict[str, str]: è§£æç»“æœï¼ŒåŒ…å«subject_id, motion_type, additional_info
        """
        filename = filepath.stem  # ä¸åŒ…å«æ‰©å±•åçš„æ–‡ä»¶å
        parts = filename.split('_')
        
        if len(parts) < 2:
            # å¦‚æœæ–‡ä»¶åæ ¼å¼ä¸ç¬¦åˆé¢„æœŸï¼Œè¿”å›é»˜è®¤å€¼
            return {
                "subject_id": "unknown",
                "motion_type": "unknown", 
                "additional_info": filename,
                "filename": filename
            }
        
        subject_id = parts[0]  # è¢«è¯•IDï¼Œå¦‚P1, P2, P3
        
        # è¯†åˆ«åŠ¨ä½œç±»å‹
        motion_type = parts[1]
        additional_info = "_".join(parts[2:]) if len(parts) > 2 else ""
        
        # å¦‚æœæ˜¯è¡¥å¿æ€§åŠ¨ä½œï¼ˆåŒ…å«C_ï¼‰ï¼Œåˆå¹¶å‰å‡ ä¸ªéƒ¨åˆ†ä½œä¸ºåŠ¨ä½œç±»å‹
        if len(parts) > 2 and parts[1] == 'C':
            motion_type = f"{parts[1]}_{parts[2]}"
            additional_info = "_".join(parts[3:]) if len(parts) > 3 else ""
        
        return {
            "subject_id": subject_id,
            "motion_type": motion_type,
            "additional_info": additional_info,
            "filename": filename
        }
    
    def group_files_by_subject(self, csv_files: List[Path]) -> Dict[str, List[Path]]:
        """
        æŒ‰è¢«è¯•IDåˆ†ç»„æ–‡ä»¶
        
        Args:
            csv_files (List[Path]): CSVæ–‡ä»¶åˆ—è¡¨
            
        Returns:
            Dict[str, List[Path]]: æŒ‰è¢«è¯•IDåˆ†ç»„çš„æ–‡ä»¶å­—å…¸
        """
        subject_groups = {}
        
        for file_path in csv_files:
            file_info = self.parse_filename(file_path)
            subject_id = file_info["subject_id"]
            
            if subject_id not in subject_groups:
                subject_groups[subject_id] = []
            
            subject_groups[subject_id].append(file_path)
        
        return subject_groups
    
    def group_files_by_motion(self, csv_files: List[Path]) -> Dict[str, List[Path]]:
        """
        æŒ‰åŠ¨ä½œç±»å‹åˆ†ç»„æ–‡ä»¶
        
        Args:
            csv_files (List[Path]): CSVæ–‡ä»¶åˆ—è¡¨
            
        Returns:
            Dict[str, List[Path]]: æŒ‰åŠ¨ä½œç±»å‹åˆ†ç»„çš„æ–‡ä»¶å­—å…¸
        """
        motion_groups = {}
        
        for file_path in csv_files:
            file_info = self.parse_filename(file_path)
            motion_type = file_info["motion_type"]
            
            if motion_type not in motion_groups:
                motion_groups[motion_type] = []
            
            motion_groups[motion_type].append(file_path)
        
        return motion_groups
    
    def split_by_subject(self, csv_files: List[Path]) -> Tuple[List[Path], List[Path]]:
        """
        æŒ‰è¢«è¯•åˆ’åˆ†æ•°æ®é›†ï¼ˆè¢«è¯•çº§åˆ«çš„åˆ’åˆ†ï¼‰
        ç¡®ä¿åŒä¸€è¢«è¯•çš„æ‰€æœ‰æ•°æ®è¦ä¹ˆåœ¨è®­ç»ƒé›†ï¼Œè¦ä¹ˆåœ¨æµ‹è¯•é›†
        
        Args:
            csv_files (List[Path]): æ‰€æœ‰CSVæ–‡ä»¶
            
        Returns:
            Tuple[List[Path], List[Path]]: (è®­ç»ƒé›†æ–‡ä»¶, æµ‹è¯•é›†æ–‡ä»¶)
        """
        subject_groups = self.group_files_by_subject(csv_files)
        subjects = list(subject_groups.keys())
        
        # éšæœºæ‰“ä¹±è¢«è¯•é¡ºåº
        random.shuffle(subjects)
        
        # è®¡ç®—è®­ç»ƒé›†è¢«è¯•æ•°é‡
        num_train_subjects = int(len(subjects) * self.train_ratio)
        
        train_subjects = subjects[:num_train_subjects]
        test_subjects = subjects[num_train_subjects:]
        
        print(f"ğŸ‘¥ æ€»è®¡ {len(subjects)} ä¸ªè¢«è¯•")
        print(f"ğŸ“š è®­ç»ƒé›†è¢«è¯• ({len(train_subjects)}): {train_subjects}")
        print(f"ğŸ§ª æµ‹è¯•é›†è¢«è¯• ({len(test_subjects)}): {test_subjects}")
        
        # æ”¶é›†å¯¹åº”çš„æ–‡ä»¶
        train_files = []
        test_files = []
        
        for subject in train_subjects:
            train_files.extend(subject_groups[subject])
        
        for subject in test_subjects:
            test_files.extend(subject_groups[subject])
        
        return train_files, test_files
    
    def split_by_motion_balanced(self, csv_files: List[Path]) -> Tuple[List[Path], List[Path]]:
        """
        æŒ‰åŠ¨ä½œç±»å‹å¹³è¡¡åˆ’åˆ†æ•°æ®é›†
        ç¡®ä¿æ¯ç§åŠ¨ä½œç±»å‹åœ¨è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸­éƒ½æœ‰åˆç†çš„åˆ†å¸ƒ
        
        Args:
            csv_files (List[Path]): æ‰€æœ‰CSVæ–‡ä»¶
            
        Returns:
            Tuple[List[Path], List[Path]]: (è®­ç»ƒé›†æ–‡ä»¶, æµ‹è¯•é›†æ–‡ä»¶)
        """
        motion_groups = self.group_files_by_motion(csv_files)
        
        train_files = []
        test_files = []
        
        print(f"ğŸ¯ æŒ‰åŠ¨ä½œç±»å‹å¹³è¡¡åˆ’åˆ†:")
        
        for motion_type, motion_files in motion_groups.items():
            # éšæœºæ‰“ä¹±è¯¥åŠ¨ä½œç±»å‹çš„æ–‡ä»¶
            motion_files_shuffled = motion_files.copy()
            random.shuffle(motion_files_shuffled)
            
            # è®¡ç®—è¯¥åŠ¨ä½œç±»å‹çš„è®­ç»ƒé›†æ–‡ä»¶æ•°é‡
            num_train = int(len(motion_files_shuffled) * self.train_ratio)
            
            motion_train = motion_files_shuffled[:num_train]
            motion_test = motion_files_shuffled[num_train:]
            
            train_files.extend(motion_train)
            test_files.extend(motion_test)
            
            print(f"  ğŸ“‹ {motion_type}: æ€»è®¡{len(motion_files)} â†’ è®­ç»ƒ{len(motion_train)} + æµ‹è¯•{len(motion_test)}")
        
        return train_files, test_files
    
    def split_random(self, csv_files: List[Path]) -> Tuple[List[Path], List[Path]]:
        """
        éšæœºåˆ’åˆ†æ•°æ®é›†ï¼ˆæ–‡ä»¶çº§åˆ«çš„éšæœºåˆ’åˆ†ï¼‰
        
        Args:
            csv_files (List[Path]): æ‰€æœ‰CSVæ–‡ä»¶
            
        Returns:
            Tuple[List[Path], List[Path]]: (è®­ç»ƒé›†æ–‡ä»¶, æµ‹è¯•é›†æ–‡ä»¶)
        """
        # éšæœºæ‰“ä¹±æ–‡ä»¶é¡ºåº
        csv_files_shuffled = csv_files.copy()
        random.shuffle(csv_files_shuffled)
        
        # è®¡ç®—è®­ç»ƒé›†æ–‡ä»¶æ•°é‡
        num_train_files = int(len(csv_files_shuffled) * self.train_ratio)
        
        train_files = csv_files_shuffled[:num_train_files]
        test_files = csv_files_shuffled[num_train_files:]
        
        print(f"ğŸ² éšæœºåˆ’åˆ†: æ€»è®¡{len(csv_files)} â†’ è®­ç»ƒ{len(train_files)} + æµ‹è¯•{len(test_files)}")
        
        return train_files, test_files
    
    def copy_files_to_dataset(self, train_files: List[Path], test_files: List[Path]):
        """
        å°†åˆ’åˆ†åçš„æ–‡ä»¶å¤åˆ¶åˆ°è®­ç»ƒé›†å’Œæµ‹è¯•é›†ç›®å½•
        
        Args:
            train_files (List[Path]): è®­ç»ƒé›†æ–‡ä»¶åˆ—è¡¨
            test_files (List[Path]): æµ‹è¯•é›†æ–‡ä»¶åˆ—è¡¨
        """
        print(f"\nğŸ“ å¼€å§‹å¤åˆ¶æ–‡ä»¶åˆ°æ•°æ®é›†ç›®å½•...")
        
        # æ¸…ç©ºè¾“å‡ºç›®å½•
        if self.train_dir.exists():
            shutil.rmtree(self.train_dir)
        if self.test_dir.exists():
            shutil.rmtree(self.test_dir)
        
        self.train_dir.mkdir(parents=True, exist_ok=True)
        self.test_dir.mkdir(parents=True, exist_ok=True)
        
        # å¤åˆ¶è®­ç»ƒé›†æ–‡ä»¶
        print(f"ğŸ“š å¤åˆ¶è®­ç»ƒé›†æ–‡ä»¶ ({len(train_files)} ä¸ª)...")
        for file_path in train_files:
            dest_path = self.train_dir / file_path.name
            shutil.copy2(file_path, dest_path)
            self.split_info["train_files"].append(str(file_path))
        
        # å¤åˆ¶æµ‹è¯•é›†æ–‡ä»¶
        print(f"ğŸ§ª å¤åˆ¶æµ‹è¯•é›†æ–‡ä»¶ ({len(test_files)} ä¸ª)...")
        for file_path in test_files:
            dest_path = self.test_dir / file_path.name
            shutil.copy2(file_path, dest_path)
            self.split_info["test_files"].append(str(file_path))
        
        print(f"âœ… æ–‡ä»¶å¤åˆ¶å®Œæˆ!")
        print(f"   è®­ç»ƒé›†: {self.train_dir}")
        print(f"   æµ‹è¯•é›†: {self.test_dir}")
    
    def analyze_dataset_statistics(self, train_files: List[Path], test_files: List[Path]):
        """
        åˆ†ææ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            train_files (List[Path]): è®­ç»ƒé›†æ–‡ä»¶åˆ—è¡¨
            test_files (List[Path]): æµ‹è¯•é›†æ–‡ä»¶åˆ—è¡¨
        """
        def analyze_file_group(files: List[Path], group_name: str):
            """åˆ†ææ–‡ä»¶ç»„çš„ç»Ÿè®¡ä¿¡æ¯"""
            subject_count = {}
            motion_count = {}
            total_samples = 0
            
            for file_path in files:
                file_info = self.parse_filename(file_path)
                subject_id = file_info["subject_id"]
                motion_type = file_info["motion_type"]
                
                # ç»Ÿè®¡è¢«è¯•æ•°é‡
                subject_count[subject_id] = subject_count.get(subject_id, 0) + 1
                
                # ç»Ÿè®¡åŠ¨ä½œç±»å‹æ•°é‡
                motion_count[motion_type] = motion_count.get(motion_type, 0) + 1
                
                # ç»Ÿè®¡æ€»æ ·æœ¬æ•°ï¼ˆè¯»å–CSVæ–‡ä»¶è¡Œæ•°ï¼‰
                try:
                    df = pd.read_csv(file_path)
                    total_samples += len(df)
                except Exception as e:
                    print(f"âš ï¸ è¯»å–æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
            
            return {
                "file_count": len(files),
                "subject_count": subject_count,
                "motion_count": motion_count,
                "total_samples": total_samples,
                "unique_subjects": len(subject_count),
                "unique_motions": len(motion_count)
            }
        
        # åˆ†æè®­ç»ƒé›†å’Œæµ‹è¯•é›†
        train_stats = analyze_file_group(train_files, "è®­ç»ƒé›†")
        test_stats = analyze_file_group(test_files, "æµ‹è¯•é›†")
        
        # å­˜å‚¨ç»Ÿè®¡ä¿¡æ¯
        self.split_info["statistics"] = {
            "train": train_stats,
            "test": test_stats
        }
        
        # æ‰“å°ç»Ÿè®¡æŠ¥å‘Š
        print(f"\nğŸ“Š æ•°æ®é›†ç»Ÿè®¡æŠ¥å‘Š:")
        print(f"=" * 60)
        
        def print_stats(stats: dict, name: str):
            print(f"\n{name}:")
            print(f"  ğŸ“ æ–‡ä»¶æ•°é‡: {stats['file_count']}")
            print(f"  ğŸ‘¥ è¢«è¯•æ•°é‡: {stats['unique_subjects']} ({list(stats['subject_count'].keys())})")
            print(f"  ğŸ¯ åŠ¨ä½œç±»å‹: {stats['unique_motions']} ({list(stats['motion_count'].keys())})")
            print(f"  ğŸ“Š æ€»æ ·æœ¬æ•°: {stats['total_samples']:,}")
            
            print(f"  ğŸ“‹ è¢«è¯•åˆ†å¸ƒ:")
            for subject, count in sorted(stats['subject_count'].items()):
                print(f"    - {subject}: {count} æ–‡ä»¶")
            
            print(f"  ğŸ“‹ åŠ¨ä½œåˆ†å¸ƒ:")
            for motion, count in sorted(stats['motion_count'].items()):
                print(f"    - {motion}: {count} æ–‡ä»¶")
        
        print_stats(train_stats, "ğŸ“š è®­ç»ƒé›†")
        print_stats(test_stats, "ğŸ§ª æµ‹è¯•é›†")
        
        print(f"\nğŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
        total_files = train_stats['file_count'] + test_stats['file_count']
        total_samples = train_stats['total_samples'] + test_stats['total_samples']
        print(f"  æ€»æ–‡ä»¶æ•°: {total_files}")
        print(f"  æ€»æ ·æœ¬æ•°: {total_samples:,}")
        print(f"  è®­ç»ƒé›†æ¯”ä¾‹: {train_stats['file_count']/total_files:.1%} ({train_stats['total_samples']/total_samples:.1%} æ ·æœ¬)")
        print(f"  æµ‹è¯•é›†æ¯”ä¾‹: {test_stats['file_count']/total_files:.1%} ({test_stats['total_samples']/total_samples:.1%} æ ·æœ¬)")
    
    def save_split_info(self):
        """ä¿å­˜åˆ’åˆ†ä¿¡æ¯åˆ°JSONæ–‡ä»¶"""
        info_file = self.output_dir / "split_info.json"
        
        with open(info_file, 'w', encoding='utf-8') as f:
            json.dump(self.split_info, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ åˆ’åˆ†ä¿¡æ¯å·²ä¿å­˜åˆ°: {info_file}")
    
    def split_dataset(self, split_method: str = "by_subject"):
        """
        æ‰§è¡Œæ•°æ®é›†åˆ’åˆ†
        
        Args:
            split_method (str): åˆ’åˆ†æ–¹æ³•ï¼Œå¯é€‰ï¼š
                - "by_subject": æŒ‰è¢«è¯•åˆ’åˆ†
                - "by_motion": æŒ‰åŠ¨ä½œç±»å‹å¹³è¡¡åˆ’åˆ†  
                - "random": éšæœºåˆ’åˆ†
        """
        print(f"ğŸš€ å¼€å§‹æ•°æ®é›†åˆ’åˆ†...")
        print(f"   æ–¹æ³•: {split_method}")
        print(f"   è¾“å…¥ç›®å½•: {self.input_dir}")
        print(f"   è¾“å‡ºç›®å½•: {self.output_dir}")
        print(f"   è®­ç»ƒé›†æ¯”ä¾‹: {self.train_ratio:.1%}")
        print(f"   æµ‹è¯•é›†æ¯”ä¾‹: {self.test_ratio:.1%}")
        print(f"   éšæœºç§å­: {self.random_seed}")
        
        # 1. æ‰«ææ–‡ä»¶
        csv_files = self.scan_files()
        if not csv_files:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°CSVæ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è¾“å…¥ç›®å½•")
            return
        
        # 2. æ ¹æ®æ–¹æ³•åˆ’åˆ†
        if split_method == "by_subject":
            train_files, test_files = self.split_by_subject(csv_files)
        elif split_method == "by_motion":
            train_files, test_files = self.split_by_motion_balanced(csv_files)
        elif split_method == "random":
            train_files, test_files = self.split_random(csv_files)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„åˆ’åˆ†æ–¹æ³•: {split_method}")
        
        # 3. å¤åˆ¶æ–‡ä»¶
        self.copy_files_to_dataset(train_files, test_files)
        
        # 4. ç»Ÿè®¡åˆ†æ
        self.analyze_dataset_statistics(train_files, test_files)
        
        # 5. ä¿å­˜åˆ’åˆ†ä¿¡æ¯
        self.save_split_info()
        
        print(f"\nğŸ‰ æ•°æ®é›†åˆ’åˆ†å®Œæˆ!")


def main():
    """ä¸»å‡½æ•° - å‘½ä»¤è¡Œæ¥å£"""
    parser = argparse.ArgumentParser(description="ShoulDex æ•°æ®é›†åˆ’åˆ†å·¥å…·")
    
    parser.add_argument("input_dir", 
                       help="è¾“å…¥æ•°æ®ç›®å½•è·¯å¾„ï¼ˆåŒ…å«CSVæ–‡ä»¶ï¼‰")
    
    parser.add_argument("-o", "--output_dir", 
                       default="./data/model_training",
                       help="è¾“å‡ºç›®å½•è·¯å¾„ï¼ˆé»˜è®¤: ./data/model_trainingï¼‰")
    
    parser.add_argument("-r", "--train_ratio", 
                       type=float, 
                       default=0.8,
                       help="è®­ç»ƒé›†æ¯”ä¾‹ï¼ˆé»˜è®¤: 0.8ï¼‰")
    
    parser.add_argument("-m", "--method", 
                       choices=["by_subject", "by_motion", "random"],
                       default="by_subject",
                       help="åˆ’åˆ†æ–¹æ³•ï¼ˆé»˜è®¤: by_subjectï¼‰")
    
    parser.add_argument("-s", "--seed", 
                       type=int, 
                       default=42,
                       help="éšæœºç§å­ï¼ˆé»˜è®¤: 42ï¼‰")
    
    args = parser.parse_args()
    
    # åˆ›å»ºåˆ’åˆ†å™¨å¹¶æ‰§è¡Œ
    splitter = DatasetSplitter(
        input_dir=args.input_dir,
        output_dir=args.output_dir,
        train_ratio=args.train_ratio,
        random_seed=args.seed
    )
    
    splitter.split_dataset(split_method=args.method)


if __name__ == "__main__":
    main()
